{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "\n",
    "Veamos cómo podríamos implementar el análisis discriminante lineal desde cero utilizando Python\n",
    "\n",
    "En el tutorial siguiente, trabajaremos con el conjunto de datos de vino que se puede obtener del repositorio de aprendizaje automático UCI. Afortunadamente, la biblioteca \"scitkit-learn\" proporciona los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## Librerias Y cargamos la base de datos\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# importing or loading the dataset \n",
    "dataset = pd.read_csv('breast-cancer-wisconsin.csv') \n",
    "  \n",
    "# distributing the dataset into two components X and Y \n",
    "X = dataset.iloc[:, 0:10] #Variables de entrada (Caracteristicas de cada vino)\n",
    "y = dataset.iloc[:, 10] #Variable de salida (tipo de vino)\n",
    "\n",
    "\"\"\"\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Categorical.from_codes(wine.target, wine.target_names)\n",
    "\"\"\"\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1000025   5   1  1.1  1.2  2  1.3   3  1.4  1.5  class\n",
      "0    1002945   5   4    4    5  7   10   3    2    1      2\n",
      "1    1015425   3   1    1    1  2    2   3    1    1      2\n",
      "2    1016277   6   8    8    1  3    4   3    7    1      2\n",
      "3    1017023   4   1    1    3  2    1   3    1    1      2\n",
      "4    1017122   8  10   10    8  7   10   9    7    1      4\n",
      "5    1018099   1   1    1    1  2   10   3    1    1      2\n",
      "6    1018561   2   1    2    1  2    1   3    1    1      2\n",
      "7    1033078   2   1    1    1  2    1   1    1    5      2\n",
      "8    1033078   4   2    1    1  2    1   2    1    1      2\n",
      "9    1035283   1   1    1    1  1    1   3    1    1      2\n",
      "10   1036172   2   1    1    1  2    1   2    1    1      2\n",
      "11   1041801   5   3    3    3  2    3   4    4    1      4\n",
      "12   1043999   1   1    1    1  2    3   3    1    1      2\n",
      "13   1044572   8   7    5   10  7    9   5    5    4      4\n",
      "14   1047630   7   4    6    4  6    1   4    3    1      4\n",
      "15   1048672   4   1    1    1  2    1   2    1    1      2\n",
      "16   1049815   4   1    1    1  2    1   3    1    1      2\n",
      "17   1050670  10   7    7    6  4   10   4    1    2      4\n",
      "18   1050718   6   1    1    1  2    1   3    1    1      2\n",
      "19   1054590   7   3    2   10  5   10   5    4    4      4\n",
      "20   1054593  10   5    5    3  6    7   7   10    1      4\n",
      "21   1056784   3   1    1    1  2    1   2    1    1      2\n",
      "22   1057013   8   4    5    1  2    1   7    3    1      4\n",
      "23   1059552   1   1    1    1  2    1   3    1    1      2\n",
      "24   1065726   5   2    3    4  2    7   3    6    1      4\n",
      "25   1066373   3   2    1    1  1    1   2    1    1      2\n",
      "26   1066979   5   1    1    1  2    1   2    1    1      2\n",
      "27   1067444   2   1    1    1  2    1   2    1    1      2\n",
      "28   1070935   1   1    3    1  2    1   1    1    1      2\n",
      "29   1070935   3   1    1    1  1    1   2    1    1      2\n",
      "..       ...  ..  ..  ...  ... ..  ...  ..  ...  ...    ...\n",
      "668  1350423   5  10   10    8  5    5   7   10    1      4\n",
      "669  1352848   3  10    7    8  5    8   7    4    1      4\n",
      "670  1353092   3   2    1    2  2    1   3    1    1      2\n",
      "671  1354840   2   1    1    1  2    1   3    1    1      2\n",
      "672  1354840   5   3    2    1  3    1   1    1    1      2\n",
      "673  1355260   1   1    1    1  2    1   2    1    1      2\n",
      "674  1365075   4   1    4    1  2    1   1    1    1      2\n",
      "675  1365328   1   1    2    1  2    1   2    1    1      2\n",
      "676  1368267   5   1    1    1  2    1   1    1    1      2\n",
      "677  1368273   1   1    1    1  2    1   1    1    1      2\n",
      "678  1368882   2   1    1    1  2    1   1    1    1      2\n",
      "679  1369821  10  10   10   10  5   10  10   10    7      4\n",
      "680  1371026   5  10   10   10  4   10   5    6    3      4\n",
      "681  1371920   5   1    1    1  2    1   3    2    1      2\n",
      "682   466906   1   1    1    1  2    1   1    1    1      2\n",
      "683   466906   1   1    1    1  2    1   1    1    1      2\n",
      "684   534555   1   1    1    1  2    1   1    1    1      2\n",
      "685   536708   1   1    1    1  2    1   1    1    1      2\n",
      "686   566346   3   1    1    1  2    1   2    3    1      2\n",
      "687   603148   4   1    1    1  2    1   1    1    1      2\n",
      "688   654546   1   1    1    1  2    1   1    1    8      2\n",
      "689   654546   1   1    1    3  2    1   1    1    1      2\n",
      "690   695091   5  10   10    5  4    5   4    4    1      4\n",
      "691   714039   3   1    1    1  2    1   1    1    1      2\n",
      "692   763235   3   1    1    1  2    1   2    1    2      2\n",
      "693   776715   3   1    1    1  3    2   1    1    1      2\n",
      "694   841769   2   1    1    1  2    1   1    1    1      2\n",
      "695   888820   5  10   10    3  7    3   8   10    2      4\n",
      "696   897471   4   8    6    4  3    4  10    6    1      4\n",
      "697   897471   4   8    8    5  4    5  10    4    1      4\n",
      "\n",
      "[698 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creamos un DataFrame que contiene tanto las características como las clases.\n",
    "df = X.join(pd.Series(y, name='class'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>1.107826e+06</td>\n",
       "      <td>1.003505e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.951860e+00</td>\n",
       "      <td>7.195021e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.326039e+00</td>\n",
       "      <td>6.572614e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <td>1.444201e+00</td>\n",
       "      <td>6.560166e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>1.365427e+00</td>\n",
       "      <td>5.547718e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.120350e+00</td>\n",
       "      <td>5.298755e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3</th>\n",
       "      <td>1.336980e+00</td>\n",
       "      <td>7.572614e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.098468e+00</td>\n",
       "      <td>5.979253e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>1.291028e+00</td>\n",
       "      <td>5.863071e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>1.063457e+00</td>\n",
       "      <td>2.589212e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    2             4\n",
       "1000025  1.107826e+06  1.003505e+06\n",
       "5        2.951860e+00  7.195021e+00\n",
       "1        1.326039e+00  6.572614e+00\n",
       "1.1      1.444201e+00  6.560166e+00\n",
       "1.2      1.365427e+00  5.547718e+00\n",
       "2        2.120350e+00  5.298755e+00\n",
       "1.3      1.336980e+00  7.572614e+00\n",
       "3        2.098468e+00  5.979253e+00\n",
       "1.4      1.291028e+00  5.863071e+00\n",
       "1.5      1.063457e+00  2.589212e+00\n",
       "class    2.000000e+00  4.000000e+00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada clase, creamos un vector con las medias de cada característica\n",
    "\n",
    "class_feature_means = pd.DataFrame()\n",
    "for c, rows in df.groupby('class'):\n",
    "    class_feature_means[c] = rows.mean()\n",
    "class_feature_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10 into shape (13,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7f9b35cc2c04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_feature_means\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mwithin_class_scatter_matrix\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 10 into shape (13,1)"
     ]
    }
   ],
   "source": [
    "#Luego, conectamos los \"mean vectors\" (mi) \n",
    "#para obtener la matriz de dispersión dentro de la clase.\n",
    "\n",
    "within_class_scatter_matrix = np.zeros((13,13))\n",
    "for c, rows in df.groupby('class'):\n",
    "    rows = rows.drop(['class'], axis=1)\n",
    "    s = np.zeros((13,13))\n",
    "    \n",
    "for index, row in rows.iterrows():\n",
    "        x, mc = row.values.reshape(13,1), class_feature_means[c].values.reshape(13,1)\n",
    "        s += (x - mc).dot((x - mc).T)\n",
    "        within_class_scatter_matrix += s\n",
    "\n",
    "\n",
    "# A continuación, calculamos la matriz de dispersión entre clases \n",
    "\n",
    "feature_means = df.mean()\n",
    "between_class_scatter_matrix = np.zeros((13,13))\n",
    "for c in class_feature_means:    \n",
    "    n = len(df.loc[df['class'] == c].index)\n",
    "    \n",
    "    mc, m = class_feature_means[c].values.reshape(13,1), feature_means.values.reshape(13,1)\n",
    "    \n",
    "    between_class_scatter_matrix += n * (mc - m).dot((mc - m).T)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Luego, resolvemos el problema del valor propio generalizado para obtener los discriminantes lineales\n",
    "\n",
    "eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(within_class_scatter_matrix).dot(between_class_scatter_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores propios con los valores propios más altos llevan la mayor cantidad de información sobre la distribución de los datos. Por lo tanto, clasificamos los valores propios de mayor a menor y seleccionamos los primeros k vectores propios. Con el fin de garantizar que el valor propio se asigne al mismo vector propio después de la clasificación, los colocamos en una matriz temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\n",
    "pairs = sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "for pair in pairs:\n",
    "    print(pair[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero, creamos una matriz W con los dos primeros vectores propios.\n",
    "w_matrix = np.hstack((pairs[0][1].reshape(13,1), pairs[1][1].reshape(13,1))).real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, guardamos el producto escalar de X y W en una nueva matriz Y.\n",
    "\n",
    "Donde X es una matriz n × d con n muestras y d dimensiones, e Y es una matriz n × k con n muestras y dimensiones k (k <n), en otras palabras, Y se compone de los componentes LDA, o dicho de otra manera, el nuevo espacio de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda = np.array(X.dot(w_matrix))\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['class'])\n",
    "\n",
    "#Luego, graficamos los datos en función de los dos componentes LDA y usamos un color diferente para cada clase.\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    X_lda[:,1],\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos la clase “LinearDiscriminantAnalysis” disponible en la librería “scikit-learn”\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Podemos acceder a la siguiente propiedad para obtener la variance explained\" pora cada componente.\n",
    "\n",
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al igual que antes, \"ploteamos\" los dos componentes LDA.\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    X_lda[:,1],\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, veamos si podemos crear un modelo para clasificar las características LDA, dividimos los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Luego, construimos y entrenamos un ”Decision Tree”. Después de predecir la categoría de cada muestra en el conjunto de pruebas, creamos una matriz de confusión para evaluar el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lda, y, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprara un poco y ver que los resultados son relevantes usamos el Análisis de componentes principales o PCA\n",
    "\n",
    "Podemos ver que PCA seleccionó los componentes que darían lugar a la mayor difusión (retener la mayor cantidad de información) y no necesariamente los que maximizan la separación entre clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X, y)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.scatter(\n",
    "    X_pca[:,0],\n",
    "    X_pca[:,1],\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
